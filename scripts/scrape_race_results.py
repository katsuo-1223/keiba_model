from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
import pandas as pd
import time
import os

# å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
input_csv = "data/raw/race_urls_jan2024_cleaned.csv"
urls_df = pd.read_csv(input_csv)
race_urls = urls_df["Race URL"].dropna().tolist()

# Seleniumã®è¨­å®šï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ï¼‰
options = Options()
options.add_argument("--headless")

# ä¿®æ­£ã•ã‚ŒãŸåˆæœŸåŒ–æ–¹æ³•
service = Service("/usr/local/bin/chromedriver")
driver = webdriver.Chrome(service=service, options=options)

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
output_dir = "data/raw"
os.makedirs(output_dir, exist_ok=True)

# çµæœæ ¼ç´ç”¨ãƒªã‚¹ãƒˆ
all_results = []

# ãƒ¬ãƒ¼ã‚¹çµæœè¡¨ã®æŠ½å‡ºé–¢æ•°
def extract_race_result(url):
    try:
        driver.get(url)
        time.sleep(2)  # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¾…ã¡

        tables = driver.find_elements(By.TAG_NAME, "table")
        for table in tables:
            html = table.get_attribute('outerHTML')
            df_list = pd.read_html(html)
            for df in df_list:
                if any(col in df.columns for col in ['Horse', 'é¦¬å']):
                    df['Source URL'] = url
                    return df
    except Exception as e:
        print(f"âŒ Error processing {url}: {e}")
    return None

# å„URLã‚’å‡¦ç†
for i, url in enumerate(race_urls, 1):
    print(f"ğŸ”„ Processing {i}/{len(race_urls)}: {url}")
    result_df = extract_race_result(url)
    if result_df is not None:
        all_results.append(result_df)

# çµæœã‚’CSVã«ä¿å­˜
if all_results:
    combined_df = pd.concat(all_results, ignore_index=True)
    output_path = os.path.join(output_dir, "race_results_jan2024.csv")
    combined_df.to_csv(output_path, index=False)
    print(f"âœ… Saved combined results to {output_path}")
else:
    print("âš ï¸ No race results were extracted.")

# ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã‚‹
driver.quit()