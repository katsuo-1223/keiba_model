# scripts/kaggle/train_lgbm_place_baseline.py
"""
Kaggle JRA ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸ LightGBM ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆè¤‡å‹äºˆæ¸¬ï¼‰å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

- å…¥åŠ›: data/processed/kaggle/train_race_result_basic.csv
    - å…ˆé ­ã« ID æƒ…å ±:
        ãƒ¬ãƒ¼ã‚¹ID, ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜, ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰, ç«¶é¦¬å ´å, é¦¬ç•ª, é¦¬å
    - æœ«å°¾ã«ç›®çš„å¤‰æ•°:
        target_win, target_place
    - ãã‚Œä»¥å¤–ã®åˆ—ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨ï¼ˆæ•°å€¤ï¼‹one-hot æ¸ˆã¿åˆ—ã‚’æƒ³å®šï¼‰

- å‡ºåŠ›:
    - models/kaggle/lgbm_place_baseline.txt      : å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    - data/processed/kaggle/lgbm_place_pred.csv : æ¤œè¨¼æœŸé–“ã§ã®äºˆæ¸¬çµæœï¼‹IDï¼‹ç›®çš„å¤‰æ•°
    - å­¦ç¿’ãƒ»æ¤œè¨¼ã® AUC / logloss ã‚’æ¨™æº–å‡ºåŠ›

â€» äº‹å‰ã«ä»¥ä¸‹ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãŠãã“ã¨:
    pip install lightgbm scikit-learn
"""

from __future__ import annotations

import os
from pathlib import Path
from typing import List, Tuple

import lightgbm as lgb
import numpy as np
import pandas as pd
from sklearn.metrics import roc_auc_score, log_loss

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’æ¨å®šï¼ˆã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰2ã¤ä¸Šã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰
ROOT = Path(__file__).resolve().parents[2]
INPUT_PATH = ROOT / "data" / "processed" / "kaggle" / "train_race_result_basic.csv"
MODEL_DIR = ROOT / "models" / "kaggle"
PRED_PATH = ROOT / "data" / "processed" / "kaggle" / "lgbm_place_pred.csv"


def load_data(path: Path) -> pd.DataFrame:
    """å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã€‚"""
    if not path.exists():
        raise FileNotFoundError(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {path}")
    df = pd.read_csv(path)
    return df


def train_valid_split_by_date(
    df: pd.DataFrame,
    date_col: str = "ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜",
    split_date: str = "2018-01-01",
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜ã§æ™‚ç³»åˆ—åˆ†å‰²ã™ã‚‹ã€‚

    ä¾‹:
        ï½2017å¹´åˆ†      â†’ train
        2018å¹´ä»¥é™åˆ†    â†’ valid
    """
    # æ—¥ä»˜å‹ã«å¤‰æ›ï¼ˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯è‡ªå‹•æ¨å®šï¼‰
    df = df.copy()
    df[date_col] = pd.to_datetime(df[date_col])

    split_ts = pd.to_datetime(split_date)

    df_train = df[df[date_col] < split_ts].copy()
    df_valid = df[df[date_col] >= split_ts].copy()

    if len(df_train) == 0 or len(df_valid) == 0:
        raise ValueError(
            f"train/valid ã®ã„ãšã‚Œã‹ãŒ 0 è¡Œã§ã™ã€‚split_date={split_date} ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚"
        )

    return df_train, df_valid


def build_feature_matrix(
    df: pd.DataFrame,
    id_cols: List[str],
    target_cols: List[str],
) -> Tuple[pd.DataFrame, pd.Series]:
    """
    ID åˆ—ã¨ç›®çš„å¤‰æ•°åˆ—ã‚’é™¤ã„ãŸã‚‚ã®ã‚’ç‰¹å¾´é‡è¡Œåˆ— X ã¨ã—ã¦è¿”ã™ã€‚
    target_place ã‚’ç›®çš„å¤‰æ•° y ã«ä½¿ç”¨ã€‚
    """
    missing = [c for c in id_cols + target_cols if c not in df.columns]
    if missing:
        raise KeyError(f"å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing}")

    feature_cols = [c for c in df.columns if c not in id_cols + target_cols]

    X = df[feature_cols].copy()
    y = df["target_place"].astype(int)

    return X, y


def train_lightgbm_baseline(
    X_train,
    y_train,
    X_valid,
    y_valid,
) -> lgb.Booster:
    print("[lgbm] Dataset æº–å‚™")
    train_data = lgb.Dataset(X_train, label=y_train)
    valid_data = lgb.Dataset(X_valid, label=y_valid)

    params = {
        "objective": "binary",
        "metric": ["auc", "binary_logloss"],
        "learning_rate": 0.05,
        "num_leaves": 31,
        "max_depth": -1,
        "feature_fraction": 0.8,
        "bagging_fraction": 0.8,
        "bagging_freq": 5,
        "verbose": -1,
        "seed": 42,
    }

    print("[lgbm] å­¦ç¿’é–‹å§‹ï¼ˆLightGBM 4.x callbacksç‰ˆï¼‰")

    # ğŸ‘‡ LightGBM 4.x ã®æ–°ã—ã„ early_stopping
    model = lgb.train(
        params=params,
        train_set=train_data,
        num_boost_round=2000,
        valid_sets=[train_data, valid_data],
        valid_names=["train", "valid"],
        callbacks=[
            lgb.early_stopping(stopping_rounds=100),
            lgb.log_evaluation(period=50),
        ],
    )

    print("[lgbm] å­¦ç¿’å®Œäº†ã€‚æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡")
    y_pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)
    auc = roc_auc_score(y_valid, y_pred_valid)
    ll = log_loss(y_valid, y_pred_valid)

    print(f"[lgbm] Validation AUC:     {auc:.4f}")
    print(f"[lgbm] Validation logloss: {ll:.4f}")
    print(f"[lgbm] best_iteration:     {model.best_iteration}")

    return model, y_pred_valid

def save_model(model: lgb.Booster, path: Path) -> None:
    """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ä¿å­˜ã€‚"""
    path.parent.mkdir(parents=True, exist_ok=True)
    model.save_model(str(path))
    print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {path}")


def save_valid_prediction(
    df_valid: pd.DataFrame,
    y_pred: np.ndarray,
    id_cols: List[str],
    target_cols: List[str],
    path: Path,
) -> None:
    """
    æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã™ã‚‹äºˆæ¸¬å€¤ã‚’ CSV å‡ºåŠ›ã€‚
    - ID æƒ…å ±
    - ç›®çš„å¤‰æ•° (target_win, target_place)
    - äºˆæ¸¬ç¢ºç‡ pred_place
    """
    path.parent.mkdir(parents=True, exist_ok=True)

    out_df = df_valid[id_cols + target_cols].copy()
    out_df["pred_place"] = y_pred

    out_df.to_csv(path, index=False)
    print(f"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®äºˆæ¸¬çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {path}")

def main() -> None:
    print("=== train_lgbm_place_baseline.py å®Ÿè¡Œé–‹å§‹ ===")
    print(f"[INFO] ROOT:       {ROOT}")
    print(f"[INFO] INPUT_PATH: {INPUT_PATH}")

    df = load_data(INPUT_PATH)

    id_cols = ["ãƒ¬ãƒ¼ã‚¹ID", "ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜", "ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰", "ç«¶é¦¬å ´å", "é¦¬ç•ª", "é¦¬å"]
    target_cols = ["target_win", "target_place"]

    df_train, df_valid = train_valid_split_by_date(
        df, date_col="ãƒ¬ãƒ¼ã‚¹æ—¥ä»˜", split_date="2018-01-01"
    )

    X_train, y_train = build_feature_matrix(df_train, id_cols=id_cols, target_cols=target_cols)
    X_valid, y_valid = build_feature_matrix(df_valid, id_cols=id_cols, target_cols=target_cols)

    print(f"[INFO] train X: {X_train.shape}, valid X: {X_valid.shape}")

    # â­ ã“ã“ã§ã‚¿ãƒ—ãƒ«ã‚’å±•é–‹ã™ã‚‹
    model, y_pred_valid = train_lightgbm_baseline(X_train, y_train, X_valid, y_valid)

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    MODEL_DIR.mkdir(parents=True, exist_ok=True)
    model_path = MODEL_DIR / "lgbm_place_baseline.txt"
    save_model(model, model_path)

    # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¸ã®äºˆæ¸¬çµæœã‚’ä¿å­˜ï¼ˆä»Šå¾Œ ROI è¨ˆç®—ãªã©ã«ä½¿ç”¨ï¼‰
    save_valid_prediction(
        df_valid=df_valid,
        y_pred=y_pred_valid,
        id_cols=id_cols,
        target_cols=target_cols,
        path=PRED_PATH,
    )

    print("=== æ­£å¸¸çµ‚äº† ===")


if __name__ == "__main__":
    main()